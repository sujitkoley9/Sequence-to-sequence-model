{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Machine Translator (English to Hindi).ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujitkoley9/Sequence-to-sequence-model/blob/master/Machine_Translator_(English_to_Hindi).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pGQdMa-m-8M",
        "colab_type": "text"
      },
      "source": [
        "<b>Important Link:</b>\n",
        "1. https://www.youtube.com/watch?v=QuELiw8tbx8&feature=youtu.be&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6&t=1190\n",
        "2. https://medium.com/analytics-vidhya/machine-translation-encoder-decoder-model-7e4867377161\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L2pfbArm-8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eBaF-44oHzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuwwEzEHm-8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkJ8YBtdm-8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "import io\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAOmRSmym-8f",
        "colab_type": "text"
      },
      "source": [
        "# Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVogp7iom-8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fa72c82f-5112-43d0-e1eb-cff73901f8a8"
      },
      "source": [
        "# Assign the data path.\n",
        "data_path = \"hin.txt\"\n",
        "\n",
        "# Read in the data.\n",
        "lines = io.open(data_path, encoding = \"utf-8\").read().split(\"\\n\")\n",
        "lines  = lines[:-1]\n",
        "print(lines[1])\n",
        "# Split the data into input and target sequences.\n",
        "lines = [line.split(\"\\t\") for line in lines]\n",
        "print(lines[0])\n",
        "# We define the starting signal to be \"\\t\" and the\n",
        "# ending signal to be \"\\n\". These signals tell the\n",
        "# model that when it sees \"\\t\" it should start\n",
        "# producing its translation and produce \"\\n\" when\n",
        "# it wants to end its translation. Let us add\n",
        "# \"\\t\" to the start and \"\\n\" to the end \n",
        "# of all input and output sentences.\n",
        "lines = [(\"\\t\" + line[0] + \"\\n\", \"\\t\" + line[1] + \"\\n\") for\n",
        "            line in lines]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jump.\tउछलो.\n",
            "['Help!', 'बचाओ!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK3R9V8rm-8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dd932f47-9aea-491d-db6e-ee650caa37a4"
      },
      "source": [
        "print (lines[0][1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tबचाओ!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnX5n5nPm-8p",
        "colab_type": "text"
      },
      "source": [
        "# Figure out the Best Lengths of Sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN49ttspm-8q",
        "colab_type": "text"
      },
      "source": [
        "## Compute Sentence Lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9iokVoym-8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute the input and output lengths.\n",
        "input_lengths = np.array([len(line[0]) for line in lines])\n",
        "output_lengths = np.array([len(line[1]) for line in lines])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAV0_q92m-8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3fe32dea-7d47-4eec-efd8-c0f40812bb30"
      },
      "source": [
        "print(len(input_lengths))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq5ff1XYm-80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "bb42b998-7186-40ca-d665-25be54ea5efc"
      },
      "source": [
        "plt.hist(input_lengths)\n",
        "plt.axis([75,80, 0 , 120])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[75, 80, 0, 120]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDTH6ktQQoy9JDTH6ktQQoy9JDfk/I9DBpdq/kk4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2V4oQd9m-85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "0ff7f1c8-f412-4cd7-c45c-7a1f0b56f234"
      },
      "source": [
        "plt.hist(output_lengths)\n",
        "plt.axis([85,89,0,20])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[85, 89, 0, 20]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAASh0lEQVR4nO3df7CmdV3/8eerXaVAxCWEEEjINoya\nwDqtlTqp6LpsJFRMsZWtSrNlOWXf78w3rJksmmZo+qbfKZqYTTawDK0UYwKFHcvQGfxxdltk+SUb\nYuyysen6XTRMY3v3x32dzxyP9+Gcva/73Oduej5m7jnX9bk+n+t6n4ubfd3Xr/ukqpAkCeDrVrsA\nSdL0MBQkSY2hIElqDAVJUmMoSJIaQ0GS1CwZCknOSvL3Se5Nck+SX+7aT06yM8mD3c91i4zf2vV5\nMMnWcf8CkqTxyVLPKSQ5HTi9qnYnORHYBVwKvBY4XFVXJ7kSWFdVv7pg7MnALDADVDf2e6rq82P/\nTSRJvS15pFBVB6tqdzf9BeA+4AzgEuCGrtsNDIJioVcBO6vqcBcEO4FN4yhckjR+a4+lc5KzgRcA\nHwNOq6qD3aJ/AU4bMuQM4JF58/u7tmHr3gZsAzjhhBO+5/nPf/6xlCZJ/6Pt2rXrs1X17L7rWXYo\nJHkG8B7gTVX1eJK2rKoqSa/vy6iq7cB2gJmZmZqdne2zOkn6HyXJZ8axnmXdfZTkaQwC4Z1V9d6u\n+bHuesPcdYdDQ4YeAM6aN39m1yZJmkLLufsowHXAfVX11nmLbgbm7ibaCvzNkOG3ARuTrOvuTtrY\ntUmSptByjhReBLwGeHmSPd1rM3A18MokDwKv6OZJMpPk7QBVdRj4beAT3euqrk2SNIWWvCV1NXhN\nQZKOTZJdVTXTdz0+0SxJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMo\nSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJzdrVLmCYuw8c4ewrb1ntMiT18PDVP7TaJWgEHilIkpol\njxSS7AAuBg5V1Xd2be8Gzu26PAv4/1V1wZCxDwNfAI4CT47jT8VJklbOck4fXQ9cA7xjrqGqfmJu\nOsnvA0eeYvzLquqzoxYoSZqcJUOhqu5IcvawZUkC/Djw8vGWJUlaDX2vKbwEeKyqHlxkeQG3J9mV\nZFvPbUmSVljfu4+2ADc+xfIXV9WBJKcCO5PcX1V3DOvYhcY2gDXPfHbPsiRJoxj5SCHJWuBHgXcv\n1qeqDnQ/DwE3ARueou/2qpqpqpk1x580almSpB76nD56BXB/Ve0ftjDJCUlOnJsGNgJ7e2xPkrTC\nlgyFJDcCdwLnJtmf5Ipu0eUsOHWU5DlJbu1mTwM+kuQu4OPALVX1gfGVLkkat+XcfbRlkfbXDml7\nFNjcTT8EnN+zPknSBPlEsySpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJ\njaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJapYMhSQ7khxKsnde228mOZBk\nT/favMjYTUkeSLIvyZXjLFySNH7LOVK4Htg0pP1tVXVB97p14cIka4A/Ai4CzgO2JDmvT7GSpJW1\nZChU1R3A4RHWvQHYV1UPVdVXgHcBl4ywHknShPS5pvDGJJ/sTi+tG7L8DOCRefP7u7ahkmxLMptk\n9ugTR3qUJUka1aih8MfA84ALgIPA7/ctpKq2V9VMVc2sOf6kvquTJI1gpFCoqseq6mhV/SfwJwxO\nFS10ADhr3vyZXZskaUqNFApJTp83+yPA3iHdPgGsT3JOkqcDlwM3j7I9SdJkrF2qQ5IbgZcCpyTZ\nD7wFeGmSC4ACHgZ+ruv7HODtVbW5qp5M8kbgNmANsKOq7lmR30KSNBZLhkJVbRnSfN0ifR8FNs+b\nvxX4mttVJUnTySeaJUmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJ\nUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWqWDIUkO5IcSrJ3XtvvJbk/ySeT3JTkWYuM\nfTjJ3Un2JJkdZ+GSpPFbzpHC9cCmBW07ge+squ8CPgW8+SnGv6yqLqiqmdFKlCRNypKhUFV3AIcX\ntN1eVU92sx8FzlyB2iRJEzaOawqvB96/yLICbk+yK8m2p1pJkm1JZpPMHn3iyBjKkiQdq7V9Bif5\ndeBJ4J2LdHlxVR1IciqwM8n93ZHH16iq7cB2gONOX1996pIkjWbkI4UkrwUuBn6qqob+I15VB7qf\nh4CbgA2jbk+StPJGCoUkm4D/A7y6qp5YpM8JSU6cmwY2AnuH9ZUkTYfl3JJ6I3AncG6S/UmuAK4B\nTmRwSmhPkmu7vs9Jcms39DTgI0nuAj4O3FJVH1iR30KSNBZLXlOoqi1Dmq9bpO+jwOZu+iHg/F7V\nSZImyieaJUmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIa\nQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWqWFQpJdiQ5lGTvvLaTk+xM8mD3c90iY7d2fR5MsnVc\nhUuSxm+5RwrXA5sWtF0JfLCq1gMf7Oa/SpKTgbcALwQ2AG9ZLDwkSatvWaFQVXcAhxc0XwLc0E3f\nAFw6ZOirgJ1VdbiqPg/s5GvDRZI0JfpcUzitqg520/8CnDakzxnAI/Pm93dtXyPJtiSzSWaPPnGk\nR1mSpFGN5UJzVRVQPdexvapmqmpmzfEnjaMsSdIx6hMKjyU5HaD7eWhInwPAWfPmz+zaJElTqE8o\n3AzM3U20FfibIX1uAzYmWdddYN7YtUmSptByb0m9EbgTODfJ/iRXAFcDr0zyIPCKbp4kM0neDlBV\nh4HfBj7Rva7q2iRJU2jtcjpV1ZZFFl04pO8s8LPz5ncAO0aqTpI0UT7RLElqDAVJUmMoSJIaQ0GS\n1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJ\nagwFSVIzcigkOTfJnnmvx5O8aUGflyY5Mq/Pb/QvWZK0Upb1N5qHqaoHgAsAkqwBDgA3Den64aq6\neNTtSJImZ1ynjy4E/qmqPjOm9UmSVsG4QuFy4MZFln1/kruSvD/Jdyy2giTbkswmmT36xJExlSVJ\nOha9QyHJ04FXA381ZPFu4LlVdT7wh8D7FltPVW2vqpmqmllz/El9y5IkjWAcRwoXAbur6rGFC6rq\n8ar6Yjd9K/C0JKeMYZuSpBUwjlDYwiKnjpJ8U5J00xu67X1uDNuUJK2Ake8+AkhyAvBK4Ofmtf08\nQFVdC1wGvCHJk8CXgMurqvpsU5K0cnqFQlX9G/CNC9qunTd9DXBNn21IkibHJ5olSY2hIElqDAVJ\nUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIk\nqTEUJEmNoSBJanqHQpKHk9ydZE+S2SHLk+QPkuxL8skk3913m5KkldHrbzTP87Kq+uwiyy4C1nev\nFwJ/3P2UJE2ZSZw+ugR4Rw18FHhWktMnsF1J0jEaRygUcHuSXUm2DVl+BvDIvPn9XdtXSbItyWyS\n2aNPHBlDWZKkYzWO00cvrqoDSU4Fdia5v6ruONaVVNV2YDvAcaevrzHUJUk6Rr2PFKrqQPfzEHAT\nsGFBlwPAWfPmz+zaJElTplcoJDkhyYlz08BGYO+CbjcDP9PdhfR9wJGqOthnu5KkldH39NFpwE1J\n5tb1F1X1gSQ/D1BV1wK3ApuBfcATwOt6blOStEJ6hUJVPQScP6T92nnTBfxin+1IkibDJ5olSY2h\nIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQ\nkCQ1hoIkqTEUJEmNoSBJakYOhSRnJfn7JPcmuSfJLw/p89IkR5Ls6V6/0a9cSdJK6vM3mp8E/ndV\n7U5yIrAryc6qundBvw9X1cU9tiNJmpCRjxSq6mBV7e6mvwDcB5wxrsIkSZM3lmsKSc4GXgB8bMji\n709yV5L3J/mOcWxPkrQy+pw+AiDJM4D3AG+qqscXLN4NPLeqvphkM/A+YP0i69kGbANY88xn9y1L\nkjSCXkcKSZ7GIBDeWVXvXbi8qh6vqi9207cCT0tyyrB1VdX2qpqpqpk1x5/UpyxJ0oj63H0U4Drg\nvqp66yJ9vqnrR5IN3fY+N+o2JUkrq8/poxcBrwHuTrKna/s14JsBqupa4DLgDUmeBL4EXF5V1WOb\nkqQVNHIoVNVHgCzR5xrgmlG3IUmaLJ9oliQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKk\nxlCQJDWGgiSpMRQkSU3vv6cgScOcfeUtq12CRuCRgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgK\nkqSmVygk2ZTkgST7klw5ZPlxSd7dLf9YkrP7bE+StLJGDoUka4A/Ai4CzgO2JDlvQbcrgM9X1bcC\nbwN+d9TtSZJWXp8jhQ3Avqp6qKq+ArwLuGRBn0uAG7rpvwYuTJIe25QkraA+X3NxBvDIvPn9wAsX\n61NVTyY5Anwj8NmFK0uyDdjWzX75M7978d4etU3CKQz5PaaQdY6XdY6XdY7PueNYydR891FVbQe2\nAySZraqZVS7pKf13qBGsc9ysc7ysc3ySzI5jPX1OHx0Azpo3f2bXNrRPkrXAScDnemxTkrSC+oTC\nJ4D1Sc5J8nTgcuDmBX1uBrZ205cBf1dV1WObkqQVNPLpo+4awRuB24A1wI6quifJVcBsVd0MXAf8\nWZJ9wGEGwbEc20eta4L+O9QI1jlu1jle1jk+Y6kxfnCXJM3xiWZJUmMoSJKaiYZCkl9Jck+SvUlu\nTPL1Sa5P8ukke7rXBYuM3Zrkwe61dVifKanz6Lw+Cy+8T6LOJPmdJJ9Kcl+SX1pk7Grvz+XWudr7\n88Pztv9okvctMnYi+7Nnjau9Ly9Msrvb/keSfOsiY9/cfTXOA0leNY11Jjk7yZfm7c9rV6HOl3d1\n7k1yQwZ3eA4be2zvzaqayIvBg2yfBr6hm/9L4LXA9cBlS4w9GXio+7mum143bXV2/b+4yvvzdcA7\ngK/r2k+d0v25ZJ3TsD8X9HkP8DOrtT/71DgN+xL4FPDtXdsvANcPGXsecBdwHHAO8E/Amims82xg\n7yruz9czeDD427q2q4ArxvHenPTpo7XAN3SJdjzw6DLHvQrYWVWHq+rzwE5g0wrVCKPXOWnD6nwD\ncFVV/SdAVR0aMm4a9udy6py0Rf+7J3km8HJg2KfwSe7PUWuctGF1FvDMbvlJDP//6hLgXVX15ar6\nNLCPwVfqTFudk7awzn8DvlJVn+qW7wR+bMi4Y35vTiwUquoA8H+BfwYOAkeq6vZu8e8k+WSStyU5\nbsjwYV+pccYU1gnw9Ulmk3w0yaUrUeMSdT4P+ImuhvcnWT9k+DTsz+XUCau/P+dcCnywqh4fMnwi\n+7NnjbD6+/JngVuT7AdeA1w9ZPg0vDeXUyfAOUn+Mck/JHnJStS4WJ0MjhbWJpl7yvoyvvph4jnH\nvD8nFgpJ1jH4FHAO8BzghCQ/DbwZeD7wvQwOcX51UjUNM4Y6n1uDx+F/Evh/SZ434TqPA/69q+FP\ngB0rsf3lGkOdq70/52wBblyJbS/XGGpc7X35K8DmqjoT+FPgrSux/eXqWedB4Jur6gXA/wL+ojtS\nm0idwE8xeO7rbUk+DnwBODqO7U3y9NErgE9X1b9W1X8A7wV+oKoO1sCXGfwHGHaouJyv1JiGOudS\nnap6CPgQ8IJJ1sngk8B7uz43Ad81ZOyq789l1jkN+5MkpzD4733LImMntT/71Lja+/JFwPlV9bGu\nz7vnal9gtd+by6qzO731uW56F4NrH982wTp/oKrurKqXVNUG4A4G10IWOub9OclQ+Gfg+5IcnyTA\nhcB9SU4H6NouBYZ9O+ptwMYk67rU3Ni1TVWdXX3HddOnMHiD3TvJOhmcT35Z1+cHGf5GWfX9uZw6\np2R/wuDQ/G+r6t8XGTup/TlyjVOwL+8FTkoy9w/nK+fVPt/NwOUZ/IGuc4D1wMenrc4kz87gb8qQ\n5Fu6Oh+aYJ33JTm12/5xDM5cDLsD6tjfm32uih/rC/gt4H4G/6D+GYNTCH8H3N21/TnwjK7vDPD2\neWNfz+Ci0z7gddNYJ4NPFHczuHvibobcDTCBOp/F4NPi3cCdDD71TOP+XLLOadifXfuHgE0L+q7K\n/hy1xmnYl8CPzKvhQ8C3dH1fzeCmg7mxv87gk/cDwEXTWCeDi7r3AHuA3cAPr0Kdv8cgsB4A3jSu\n96ZfcyFJanyiWZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVLzXx300bSmeBM5AAAAAElFTkSu\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOoXSALXm-88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english = 78\n",
        "hindi = 87"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0IbyJcbm-8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "line1 = []\n",
        "for i in range(len(input_lengths)):\n",
        "    if(input_lengths[i]<75 and output_lengths[i]<85):\n",
        "        line1 = line1 + [lines[i]]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Ts_D4-m-9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "274c28e1-be49-4aa8-9bc9-b22f66e8d18d"
      },
      "source": [
        "print(len(line1))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuOvqCTmm-9H",
        "colab_type": "text"
      },
      "source": [
        "## Input Length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu58HjPim-9I",
        "colab_type": "text"
      },
      "source": [
        "Plotted the histogram of the length of the input sentences and choose the length that makes the most sense. \n",
        "\n",
        "The reason we don't want sentences that are too long is because the computation becomes trickier for longer sentences and the performance also degrades. However we also want as many sentences in our dataset as possible.\n",
        "\n",
        "Thus it is important to choose the right length and discard sentences longer than this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUR3ysfsm-9J",
        "colab_type": "text"
      },
      "source": [
        "## Output Length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ3eiFKAm-9K",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same for the lengths of the output sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1r4j0Aim-9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 2869  # Number of samples to train on."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCdE7q1wm-9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_texts = [(line[0]) for line in line1]\n",
        "target_texts = [(line[1]) for line in line1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAXricwom-9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_characters = set()\n",
        "target_characters = set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7MDcH6mm-9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for input_text in input_texts:\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "\n",
        "for target_text in target_texts:\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocyoFFFhm-9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "472f630d-b422-4ead-dfb3-f1ff0a2e3ffb"
      },
      "source": [
        "print(len(input_characters))\n",
        "print(len(target_characters))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72\n",
            "92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX0zSiVBm-9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHtJVtiym-9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "f62f506d-a1aa-4358-95dc-eaf2f925f8d7"
      },
      "source": [
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 2856\n",
            "Number of unique input tokens: 72\n",
            "Number of unique output tokens: 92\n",
            "Max sequence length for inputs: 74\n",
            "Max sequence length for outputs: 82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW6TDYo_m-9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFvDyVsqm-91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IgWJIWVm-95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            \n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSjNsOoDm-98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkIv_atqm--A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCntcTpfm--D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMVT7qOhm--G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f6cfd325-7f9b-4655-c1fb-adadfc77a819"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,batch_size=batch_size,epochs=epochs,validation_split=0.2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2284 samples, validate on 572 samples\n",
            "Epoch 1/100\n",
            "2284/2284 [==============================] - 36s 16ms/sample - loss: 1.2195 - val_loss: 1.9141\n",
            "Epoch 2/100\n",
            "2284/2284 [==============================] - 31s 14ms/sample - loss: 1.1349 - val_loss: 1.8452\n",
            "Epoch 3/100\n",
            "2284/2284 [==============================] - 31s 14ms/sample - loss: 1.1173 - val_loss: 1.7307\n",
            "Epoch 4/100\n",
            "2284/2284 [==============================] - 31s 14ms/sample - loss: 1.0027 - val_loss: 1.6143\n",
            "Epoch 5/100\n",
            "2284/2284 [==============================] - 31s 13ms/sample - loss: 0.9288 - val_loss: 1.5272\n",
            "Epoch 6/100\n",
            "2284/2284 [==============================] - 30s 13ms/sample - loss: 0.8763 - val_loss: 1.4800\n",
            "Epoch 7/100\n",
            "2284/2284 [==============================] - 31s 13ms/sample - loss: 0.8327 - val_loss: 1.4047\n",
            "Epoch 8/100\n",
            "2284/2284 [==============================] - 29s 13ms/sample - loss: 0.7981 - val_loss: 1.3716\n",
            "Epoch 9/100\n",
            "2284/2284 [==============================] - 29s 13ms/sample - loss: 0.7725 - val_loss: 1.3315\n",
            "Epoch 10/100\n",
            "2284/2284 [==============================] - 29s 13ms/sample - loss: 0.7510 - val_loss: 1.3009\n",
            "Epoch 11/100\n",
            "2284/2284 [==============================] - 29s 13ms/sample - loss: 0.7317 - val_loss: 1.2688\n",
            "Epoch 12/100\n",
            "2284/2284 [==============================] - 28s 12ms/sample - loss: 0.7168 - val_loss: 1.2542\n",
            "Epoch 13/100\n",
            "2284/2284 [==============================] - 28s 12ms/sample - loss: 0.7053 - val_loss: 1.2489\n",
            "Epoch 14/100\n",
            "2284/2284 [==============================] - 28s 12ms/sample - loss: 0.6921 - val_loss: 1.2098\n",
            "Epoch 15/100\n",
            "2284/2284 [==============================] - 28s 12ms/sample - loss: 0.6787 - val_loss: 1.2091\n",
            "Epoch 16/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.6680 - val_loss: 1.1980\n",
            "Epoch 17/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.6581 - val_loss: 1.1878\n",
            "Epoch 18/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.6502 - val_loss: 1.1872\n",
            "Epoch 19/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.6404 - val_loss: 1.1740\n",
            "Epoch 20/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.6324 - val_loss: 1.1629\n",
            "Epoch 21/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.6232 - val_loss: 1.1434\n",
            "Epoch 22/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.6202 - val_loss: 1.1365\n",
            "Epoch 23/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.6085 - val_loss: 1.1360\n",
            "Epoch 24/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.6008 - val_loss: 1.1287\n",
            "Epoch 25/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.5926 - val_loss: 1.1165\n",
            "Epoch 26/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.5861 - val_loss: 1.1169\n",
            "Epoch 27/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.5785 - val_loss: 1.1167\n",
            "Epoch 28/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.5717 - val_loss: 1.0995\n",
            "Epoch 29/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.5653 - val_loss: 1.0978\n",
            "Epoch 30/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.5698 - val_loss: 1.0845\n",
            "Epoch 31/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.5517 - val_loss: 1.1026\n",
            "Epoch 32/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.5457 - val_loss: 1.0852\n",
            "Epoch 33/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.5385 - val_loss: 1.0825\n",
            "Epoch 34/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.5313 - val_loss: 1.0951\n",
            "Epoch 35/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.5251 - val_loss: 1.0918\n",
            "Epoch 36/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.5191 - val_loss: 1.0871\n",
            "Epoch 37/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.5115 - val_loss: 1.0993\n",
            "Epoch 38/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.5050 - val_loss: 1.0921\n",
            "Epoch 39/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4988 - val_loss: 1.0898\n",
            "Epoch 40/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4922 - val_loss: 1.1032\n",
            "Epoch 41/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4859 - val_loss: 1.1038\n",
            "Epoch 42/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4792 - val_loss: 1.0888\n",
            "Epoch 43/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4727 - val_loss: 1.1049\n",
            "Epoch 44/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4666 - val_loss: 1.1032\n",
            "Epoch 45/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4591 - val_loss: 1.0990\n",
            "Epoch 46/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4532 - val_loss: 1.1145\n",
            "Epoch 47/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4464 - val_loss: 1.1089\n",
            "Epoch 48/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4400 - val_loss: 1.1230\n",
            "Epoch 49/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4322 - val_loss: 1.1213\n",
            "Epoch 50/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4253 - val_loss: 1.1248\n",
            "Epoch 51/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4186 - val_loss: 1.1344\n",
            "Epoch 52/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4123 - val_loss: 1.1498\n",
            "Epoch 53/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.4061 - val_loss: 1.1502\n",
            "Epoch 54/100\n",
            "2284/2284 [==============================] - 25s 11ms/sample - loss: 0.3999 - val_loss: 1.1405\n",
            "Epoch 55/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3934 - val_loss: 1.1620\n",
            "Epoch 56/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3873 - val_loss: 1.1660\n",
            "Epoch 57/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3804 - val_loss: 1.1704\n",
            "Epoch 58/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3744 - val_loss: 1.1830\n",
            "Epoch 59/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3680 - val_loss: 1.2069\n",
            "Epoch 60/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3624 - val_loss: 1.2124\n",
            "Epoch 61/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.3559 - val_loss: 1.1845\n",
            "Epoch 62/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3497 - val_loss: 1.2096\n",
            "Epoch 63/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3447 - val_loss: 1.2207\n",
            "Epoch 64/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3377 - val_loss: 1.2441\n",
            "Epoch 65/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.3338 - val_loss: 1.2512\n",
            "Epoch 66/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.3279 - val_loss: 1.2545\n",
            "Epoch 67/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3214 - val_loss: 1.2530\n",
            "Epoch 68/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.3162 - val_loss: 1.2968\n",
            "Epoch 69/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3116 - val_loss: 1.2625\n",
            "Epoch 70/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3052 - val_loss: 1.2774\n",
            "Epoch 71/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.3014 - val_loss: 1.2956\n",
            "Epoch 72/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.2939 - val_loss: 1.2969\n",
            "Epoch 73/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.2900 - val_loss: 1.3220\n",
            "Epoch 74/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.2856 - val_loss: 1.3204\n",
            "Epoch 75/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.2800 - val_loss: 1.3289\n",
            "Epoch 76/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.2759 - val_loss: 1.3669\n",
            "Epoch 77/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.2696 - val_loss: 1.3659\n",
            "Epoch 78/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.2655 - val_loss: 1.3913\n",
            "Epoch 79/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.2615 - val_loss: 1.3838\n",
            "Epoch 80/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.2575 - val_loss: 1.4033\n",
            "Epoch 81/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.2531 - val_loss: 1.4125\n",
            "Epoch 82/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.2495 - val_loss: 1.4147\n",
            "Epoch 83/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.2448 - val_loss: 1.4234\n",
            "Epoch 84/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.2401 - val_loss: 1.4418\n",
            "Epoch 85/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.2366 - val_loss: 1.4415\n",
            "Epoch 86/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.2337 - val_loss: 1.4504\n",
            "Epoch 87/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.2290 - val_loss: 1.4758\n",
            "Epoch 88/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.2266 - val_loss: 1.4547\n",
            "Epoch 89/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.2215 - val_loss: 1.4728\n",
            "Epoch 90/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.2196 - val_loss: 1.4770\n",
            "Epoch 91/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.2162 - val_loss: 1.4869\n",
            "Epoch 92/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.2118 - val_loss: 1.5121\n",
            "Epoch 93/100\n",
            "2284/2284 [==============================] - 26s 12ms/sample - loss: 0.2089 - val_loss: 1.5466\n",
            "Epoch 94/100\n",
            "2284/2284 [==============================] - 26s 11ms/sample - loss: 0.2061 - val_loss: 1.5325\n",
            "Epoch 95/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.2027 - val_loss: 1.5405\n",
            "Epoch 96/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.2002 - val_loss: 1.5525\n",
            "Epoch 97/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.1967 - val_loss: 1.5805\n",
            "Epoch 98/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.1932 - val_loss: 1.5865\n",
            "Epoch 99/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.1911 - val_loss: 1.5758\n",
            "Epoch 100/100\n",
            "2284/2284 [==============================] - 27s 12ms/sample - loss: 0.1881 - val_loss: 1.5915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa91beac940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV7oKmwmm--J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('s2s.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsXtab6lm--M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ejf9hqjm--P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXnvR_gAm--T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2d9f947-e09e-4b1f-ca8f-363e334d3134"
      },
      "source": [
        "for seq_index in range(100):\n",
        "    \n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print(input_texts[seq_index])\n",
        "    print(decoded_sentence)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "\tHelp!\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tJump.\n",
            "\n",
            "किसको पता है?\n",
            "\n",
            "-\n",
            "\tJump.\n",
            "\n",
            "किसको पता है?\n",
            "\n",
            "-\n",
            "\tJump.\n",
            "\n",
            "किसको पता है?\n",
            "\n",
            "-\n",
            "\tHello!\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tHello!\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tCheers!\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tCheers!\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tGot it?\n",
            "\n",
            "यह किताब कहीँ है?\n",
            "\n",
            "-\n",
            "\tI'm OK.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tAwesome!\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tCome in.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tGet out!\n",
            "\n",
            "यह मेरा पति लहाती है।\n",
            "\n",
            "-\n",
            "\tGo away!\n",
            "\n",
            "यह मेरा पति लाही है।\n",
            "\n",
            "-\n",
            "\tGoodbye!\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tPerfect!\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tPerfect!\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tWelcome.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tWelcome.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tHave fun.\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tHave fun.\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tHave fun.\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tI forgot.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI forgot.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI'll pay.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI'm fine.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI'm full.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tLet's go!\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tAnswer me.\n",
            "\n",
            "किसको पता है?\n",
            "\n",
            "-\n",
            "\tBirds fly.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tExcuse me.\n",
            "\n",
            "मुझे अपनी कामी मिलतें की कान सक बहुत थर कर रही है।\n",
            "\n",
            "-\n",
            "\tFantastic!\n",
            "\n",
            "क्या तुम्हें गाड़ी चलाना आता है?\n",
            "\n",
            "-\n",
            "\tI fear so.\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tI laughed.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI'm bored.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI'm broke.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI'm tired.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tIt's cold.\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tWho knows?\n",
            "\n",
            "यह मेरा पति लाही है।\n",
            "\n",
            "-\n",
            "\tWho knows?\n",
            "\n",
            "यह मेरा पति लाही है।\n",
            "\n",
            "-\n",
            "\tWho knows?\n",
            "\n",
            "यह मेरा पति लाही है।\n",
            "\n",
            "-\n",
            "\tWho knows?\n",
            "\n",
            "यह मेरा पति लाही है।\n",
            "\n",
            "-\n",
            "\tWonderful!\n",
            "\n",
            "किसको पता है?\n",
            "\n",
            "-\n",
            "\tBirds sing.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tCome on in.\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tDefinitely!\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tDon't move.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tFire burns.\n",
            "\n",
            "वह अपने किस्तर को है?\n",
            "\n",
            "-\n",
            "\tFollow him.\n",
            "\n",
            "वह अपने किस्तर को है?\n",
            "\n",
            "-\n",
            "\tI am tired.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI can swim.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI can swim.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI love you.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI love you.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI love you.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI love you.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI love you.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI will try.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI'm coming.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI'm hungry!\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI'm hungry!\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tLet him in.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tLet him in.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tLet me out!\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tOnce again.\n",
            "\n",
            "हम सब उसके बहात कार करना है।\n",
            "\n",
            "-\n",
            "\tPlease sit.\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tWhat's new?\n",
            "\n",
            "यह मेरा पति लाही है।\n",
            "\n",
            "-\n",
            "\tWhat's new?\n",
            "\n",
            "यह मेरा पति लाही है।\n",
            "\n",
            "-\n",
            "\tWho's that?\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tDon't shout.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tDon't shout.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tHe stood up.\n",
            "\n",
            "वह अपने कम्मास को स्येदारह का क्यां हरी है?\n",
            "\n",
            "-\n",
            "\tHe's strong.\n",
            "\n",
            "वह अपने कम्मास को स्येदारह का क्यां हरी है?\n",
            "\n",
            "-\n",
            "\tHow are you?\n",
            "\n",
            "तुम कितने सेल में काम करना चाहिए?\n",
            "\n",
            "-\n",
            "\tHow are you?\n",
            "\n",
            "तुम कितने सेल में काम करना चाहिए?\n",
            "\n",
            "-\n",
            "\tHow are you?\n",
            "\n",
            "तुम कितने सेल में काम करना चाहिए?\n",
            "\n",
            "-\n",
            "\tHow are you?\n",
            "\n",
            "तुम कितने सेल में काम करना चाहिए?\n",
            "\n",
            "-\n",
            "\tHow are you?\n",
            "\n",
            "तुम कितने सेल में काम करना चाहिए?\n",
            "\n",
            "-\n",
            "\tHow are you?\n",
            "\n",
            "तुम कितने सेल में काम करना चाहिए?\n",
            "\n",
            "-\n",
            "\tHow are you?\n",
            "\n",
            "तुम कितने सेल में काम करना चाहिए?\n",
            "\n",
            "-\n",
            "\tI am hungry.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI like both.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI like cake.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI like dogs.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI like math.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI'll attend.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tNobody came.\n",
            "\n",
            "मुझे देख सक गोड़ कि मैं है।\n",
            "\n",
            "-\n",
            "\tWas I wrong?\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tWhat's this?\n",
            "\n",
            "यह मेरा पति लाही है।\n",
            "\n",
            "-\n",
            "\tAre you sick?\n",
            "\n",
            "तुम कितने सेल में काम करना चाहिए?\n",
            "\n",
            "-\n",
            "\tBring him in.\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tCome with us.\n",
            "\n",
            "मुझे देखने दो।\n",
            "\n",
            "-\n",
            "\tHappy Easter!\n",
            "\n",
            "वह अपने कमरे में रो रही थी।\n",
            "\n",
            "-\n",
            "\tHas Tom left?\n",
            "\n",
            "यह मेरा बत्ता है।\n",
            "\n",
            "-\n",
            "\tHe is French.\n",
            "\n",
            "वह अपने कम्मास को स्येदारह का क्यां हरी है?\n",
            "\n",
            "-\n",
            "\tI am at home.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI can't move.\n",
            "\n",
            "मैं अपनी नादी से हफ़्ते में दो बार मिलने जाता हूँ।\n",
            "\n",
            "-\n",
            "\tI don't know.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI don't know.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n",
            "-\n",
            "\tI have a car.\n",
            "\n",
            "मैं अपनी कामा का फूँढ़ रहाँ हो।\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MstvGwEFm--X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}