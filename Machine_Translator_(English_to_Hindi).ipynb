{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Machine Translator (English to Hindi).ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujitkoley9/Sequence-to-sequence-model/blob/master/Machine_Translator_(English_to_Hindi).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pGQdMa-m-8M",
        "colab_type": "text"
      },
      "source": [
        "<b>Important Link:</b>\n",
        "1. https://www.youtube.com/watch?v=QuELiw8tbx8&feature=youtu.be&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6&t=1190\n",
        "2. https://medium.com/analytics-vidhya/machine-translation-encoder-decoder-model-7e4867377161\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L2pfbArm-8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuwwEzEHm-8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkJ8YBtdm-8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "import io\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAOmRSmym-8f",
        "colab_type": "text"
      },
      "source": [
        "# Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVogp7iom-8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign the data path.\n",
        "data_path = \"hin.txt\"\n",
        "\n",
        "# Read in the data.\n",
        "lines = io.open(data_path, encoding = \"utf-8\").read().split(\"\\n\")\n",
        "lines  = lines[:-1]\n",
        "print(lines[1])\n",
        "# Split the data into input and target sequences.\n",
        "lines = [line.split(\"\\t\") for line in lines]\n",
        "print(lines[0])\n",
        "# We define the starting signal to be \"\\t\" and the\n",
        "# ending signal to be \"\\n\". These signals tell the\n",
        "# model that when it sees \"\\t\" it should start\n",
        "# producing its translation and produce \"\\n\" when\n",
        "# it wants to end its translation. Let us add\n",
        "# \"\\t\" to the start and \"\\n\" to the end \n",
        "# of all input and output sentences.\n",
        "lines = [(\"\\t\" + line[0] + \"\\n\", \"\\t\" + line[1] + \"\\n\") for\n",
        "            line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK3R9V8rm-8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (lines[0][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnX5n5nPm-8p",
        "colab_type": "text"
      },
      "source": [
        "# Figure out the Best Lengths of Sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN49ttspm-8q",
        "colab_type": "text"
      },
      "source": [
        "## Compute Sentence Lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9iokVoym-8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute the input and output lengths.\n",
        "input_lengths = np.array([len(line[0]) for line in lines])\n",
        "output_lengths = np.array([len(line[1]) for line in lines])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAV0_q92m-8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print len(input_lengths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq5ff1XYm-80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(input_lengths)\n",
        "plt.axis([75,80, 0 , 120])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2V4oQd9m-85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(output_lengths)\n",
        "plt.axis([85,89,0,20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOoXSALXm-88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english = 78\n",
        "hindi = 87"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0IbyJcbm-8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "line1 = []\n",
        "for i in range(len(input_lengths)):\n",
        "    if(input_lengths[i]<75 and output_lengths[i]<85):\n",
        "        line1 = line1 + [lines[i]]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Ts_D4-m-9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print len(line1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuOvqCTmm-9H",
        "colab_type": "text"
      },
      "source": [
        "## Input Length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu58HjPim-9I",
        "colab_type": "text"
      },
      "source": [
        "Plotted the histogram of the length of the input sentences and choose the length that makes the most sense. \n",
        "\n",
        "The reason we don't want sentences that are too long is because the computation becomes trickier for longer sentences and the performance also degrades. However we also want as many sentences in our dataset as possible.\n",
        "\n",
        "Thus it is important to choose the right length and discard sentences longer than this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUR3ysfsm-9J",
        "colab_type": "text"
      },
      "source": [
        "## Output Length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ3eiFKAm-9K",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same for the lengths of the output sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1r4j0Aim-9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 2869  # Number of samples to train on."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCdE7q1wm-9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_texts = [(line[0]) for line in line1]\n",
        "target_texts = [(line[1]) for line in line1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAXricwom-9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_characters = set()\n",
        "target_characters = set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7MDcH6mm-9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for input_text in input_texts:\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "\n",
        "for target_text in target_texts:\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocyoFFFhm-9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print len(input_characters)\n",
        "print len(target_characters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX0zSiVBm-9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHtJVtiym-9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW6TDYo_m-9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFvDyVsqm-91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IgWJIWVm-95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            \n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSjNsOoDm-98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkIv_atqm--A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCntcTpfm--D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMVT7qOhm--G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,batch_size=batch_size,epochs=epochs,validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV7oKmwmm--J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('s2s.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsXtab6lm--M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ejf9hqjm--P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXnvR_gAm--T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for seq_index in range(100):\n",
        "    \n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print(input_texts[seq_index])\n",
        "    print(decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MstvGwEFm--X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}